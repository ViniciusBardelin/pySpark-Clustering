# pySpark-Clustering

## O que é o Spark?
O Spark é um framework de processamento de dados, desenvolvido pela Apache Software Foundation, que oferece uma abordagem eficiente e escalável para lidar com grandes conjuntos de dados em tempo real e em lote.

A arquitetura distribuída do Spark permite executar tarefas complexas de processamento de dados em paralelo, aproveitando clusters (redes) de computadores para proporcionar velocidade e escalabilidade excepcionais.

## O que é o PySpark?
PySpark é a interface Python para o Spark, permitindo aos desenvolvedores escrever código Spark utilizando a linguagem de programação Python. Essa interface é essencial para muitos desenvolvedores e cientistas de dados, pois Python é uma linguagem popular e amplamente utilizada no domínio de análise de dados e aprendizado de máquina. A documentação do PySpark se encontra [aqui](https://spark.apache.org/docs/latest/api/python/index.html).

## Projeto

Neste projeto eu manipulei, tratei dados e construi um algoritmo de clustering para simular um sistema de recomendação de músicas, assim como o Spotify recomenda músicas para os seus usuários, por exemplo.

Você pode checar os códigos no Jupyter Notebook clicando [aqui]().
